---
title: "M2.851 - Tipología y ciclo de vida de los datos Practica 2"
author: "Francisco Javier Melchor y Enrique Otero"
date: "04/01/2021"
toc: true
theme: united
output: pdf_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Paquetes
Los paquetes que se van a utilizar para el desarrollo de esta actividad, son los siguientes:

```{r, message=FALSE}
if(!require(ggplot2)){
  install.packages("ggplot2")
  library(ggplot2)
}
if(!require(arc)){
  install.packages("arc")
  library(arc)
}

if(!require(ggcorrplot)){
  install.packages("ggcorrplot")
  library(ggcorrplot)
}

if(!require(ggpubr)){
  install.packages("ggpubr")
  library(ggpubr)
}

if(!require(BSDA)){
  install.packages("BSDA")
  library(BSDA)
}
if(!require(tidyverse)){
  install.packages("tidyverse")
  library(tidyverse)
}

if(!require(lattice)){
  install.packages("lattice")
  library(lattice)
}

if(!require(caret)){
  install.packages("caret")
  library(caret)
}

if(!require(dplyr)){
  install.packages("dplyr")
  library(dplyr)
}

if(!require(lattice)){
  install.packages("lattice")
  library(lattice)
}

if(!require(plyr)){
  install.packages("plyr")
  library(plyr)
}

if(!require(rsample)){
  install.packages("rsample")
  library(rsample)
}

if(!require(yardstick)){
  install.packages("yardstick")
  library(yardstick)
}

```

# Presentación
En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas. Para hacer esta práctica tendréis que trabajar en grupos de 2 personas. Tendréis que entregar un solo archivo con el enlace Github (https://github.com) donde se encuentren las soluciones incluyendo los nombres de los componentes del equipo. Podéis utilizar la Wiki de Github para describir vuestro equipo y los diferentes archivos que corresponden a vuestra entrega. Cada miembro del equipo tendrá que contribuir con su usuario Github. Aunque no se trata del mismo enunciado, los siguientes ejemplos de ediciones anteriores os pueden servir como guía:  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Ejemplo: https://github.com/Bengis/nba-gap-cleaning  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Ejemplo complejo (archivo adjunto).


# Competencias
En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:  

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A. Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.  

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B.Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.

# Objetivos
Los objetivos concretos de esta práctica son:  

|   1. __Aprender__ a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos  
|   nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.  

|   2. __Saber__ identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación)  
|   para llevar a cabo un proyecto analítico.  

|   3. __Aprender__ a analizar los datos adecuadamente para abordar la información contenida en los datos.  

|   4. __Identificar__ la mejor representación de los resultados para aportar conclusiones sobre el problema  
|   planteado en el proceso analítico.  

|   5. __Actuar__ con los principios éticos y legales relacionados con la manipulación de datos en Tipología y ciclo  
|   de vida de los datos Práctica 2 pág 2 función del ámbito de aplicación.  

|   6. __Desarrollar__ las habilidades de aprendizaje que les permitan continuar estudiando de un modo que  
|   tendrá que ser en gran medida autodirigido o autónomo.  

|   7. __Desarrollar__ la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia  
|   de datos.  

# Descripción de la Práctica a realizar
El objetivo de esta actividad será el tratamiento de un dataset, que puede ser el creado en la práctica 1 o bien cualquier dataset libre disponible en Kaggle (https://www.kaggle.com). Algunos ejemplos de dataset con los que podéis trabajar son:  

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Red Wine Quality (https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009)  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Titanic: Machine Learning from Disaster (https://www.kaggle.com/c/titanic)  

El último ejemplo corresponde a una competición activa de Kaggle de manera que, opcionalmente, podéis aprovechar el trabajo realizado durante la práctica para entrar en esta competición.

# Preguntas y desarrollo de respuestas
Siguiendo las principales etapas de un proyecto analítico, las diferentes tareas a realizar (y justificar) son las siguientes:  

# 1. Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?
Para nuestra practica especifica hemos elegido el dataset asociado al ejemplo de Kaggle:  
__Titanic: Machine Learnin from Disaster__  

El hundimiento del Titanic es uno de los naufragios más trágicos de la historia.

El 15 de abril de 1912, durante su viaje inaugural, el RMS Titanic, ampliamente considerado "insumergible", se hundió tras chocar con un iceberg. Desafortunadamente, no había suficientes botes salvavidas para todos a bordo, lo que resultó en la muerte de 1502 de los 2224 pasajeros y la tripulación.

Si bien hubo algún elemento de suerte involucrado en sobrevivir, parece que algunos grupos de personas tenían más probabilidades de sobrevivir que otros.

En este desafío, se pide crear un modelo predictivo que responda a la pregunta: __"¿Qué tipo de personas tenían más probabilidades de sobrevivir?"__ utilizando datos de pasajeros (es decir, nombre, edad, sexo, clase socioeconómica, etc.). En términos de análitica se trata de un problema de __clasificación__, esto es, usar esas variables independientes para predecir la categoría a la que pertenece cada registro, o, dicho de otra manera, predecir si un pasajero dado va a sobrevivir o no.

El enlace de descarga de este ejemplo contiene tres ficheros:  

|   __train.csv__. Se trata del dataset _test_ sobre el que entrenamos a nuestros modelos de analítica.  
|   __test.csv__. Es el dataset donde probamos, con nuevos datos, nuestros modelos de analítica.  
|   Para este caso no se incluye el resultado (variable dependiente _Survived_) ya que es el objetivo  
|   del concurso.
|   __gender_submission.csv__. Contiene un ejemplo de como debe presentarse el formato de salida con el  
|   resultado de nuestros modelos. Se trata de un conjunto de predicciones que asumen que todas y solo  
|   mujeres sobreviven.  

Según los datos proporcionados en la web de Kaggle, las variables de los datasets son:  

| __Variable__ | __Definition__ | __Key__ | 
|:-------------|:---------------|:------- |
| __Survived__ | If passenger survived | 0 = No, 1 = Yes |
| __Pclass__ | Ticket Class | 1 = 1st, 2 = 2nd, 3 = 3rd |
| __Sex__ | Passenger Sex | |
| __Age__ | Passenger Age in years | |
| __SibSp__ | Number of sibings/spouses of the passenger aboard the Titanic | |
| __Parch__ | Number of parents/children of the passenger aboard the Titanic | |
| __Ticket__ | Ticket number | |
| __Fare__ | Passenger fare | |
| __Cabin__ | Cabin Number | |
| __Embarked__ | Port of Embarkation | |  

# 2. Integración y selección de los datos de interés a utilizar

En este caso al estar realizando el análisis de un único dataset, no es necesario realizar ninguna integración de distintas fuentes, pues sólo existe una. 

Por otro lado, con respecto a la selección, en este caso al no ser un dataset excesivamente grande y al no tener fijado un objetivo diferente que analizar todo el conjunto de sus datos y no una parte de ellos, no se realizará ninguna selección del dataset de origen ni se acotará el mismo.

# 3. Limpieza de datos
En esta sección realizaremos una limpieza del dataset incluido en el fichero __train.csv__.

Para ello, lo primero que realizaremos es la lectura del fichero __train.csv__ y comprobar como han sido interpretadas por R las variables que forman el mismo.

```{r}
ttc <- read.csv("./Data/train.csv",na.strings=c(""," ","NA"))
head(ttc)
str(ttc)
# Contamos con 891 observaciones de las 12 variables decritas al inicio de esta seccion. 
```
Como se puede observar, la mayoría de las variables han sido interpretadas correctamente por R, pero tanto la variable **Sex** como la variable **Embarked**, han sido formateadas como variables de tipo carácter (chr) y realmente son variables categóricas. Por otro lado, la variable **Survived** y **Pclass** han sido interpretadas como variables numéricas cuando realmente son variables categóricas. Procedemos a continuación a convertir las variables nombradas.

```{r}
ttc$Sex <- as.factor(ttc$Sex)
ttc$Embarked <- as.factor(ttc$Embarked)
ttc$Survived <- as.factor(ttc$Survived)
ttc$Pclass <- as.factor(ttc$Pclass)

str(ttc)
```

Por otro lado, la variable **Age**, ha sido interpretada por R como una variable numérica y no como una variable entera, lo que indica que esta posee valores decimales. Se procede a continuación a verificar cuantos casos hay de valores decimales en la variable Age.

```{r}
decimalAges<-c()

for (i in 1:(nrow(ttc))){
  if(!is.na(ttc$Age[i])){
    if(as.integer(ttc$Age[i]) != ttc$Age[i])
      decimalAges<-c(decimalAges,ttc$Age[i])
  }
}
decimalAges
length(decimalAges)
```
Como se puede observar, existen `r length(decimalAges)` casos de edades decimales. 

Para solventar esta problemática sin perder datos, procederemos a realizar un redondeo al entero más cercano y en caso de ser un valor menor que 1, lo redondearemos a uno directamente. Procedemos a continuación a realizar dicha conversión:

```{r}
roundValues <- function(x){
  if (!is.na(x['Age'])){
    if(x['Age'] < 1)
      x['Age'] = 1
    else
      x['Age'] = round(as.numeric(x['Age']))
  }
  return(x['Age'])
}


ttc$Age <- apply(ttc,1,roundValues)
ttc$Age <- as.integer(ttc$Age)
str(ttc)
```

Una vez que todas las variables han sido interpretadas correctamente, podemos proceder a realizar la limpieza y el procesamiento de los datos que contiene este dataframe.

## 3.1. ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?

A continuación se procede a comprobar si existen valores nulos o elementos vacíos en el dataframe a analizar:

```{r}
colSums(is.na(ttc))

```
Como se puede observar, existen valores faltantes en las columnas **Age, Cabin y Embarked**.

Para responder a la pregunta de *¿Cómo gestionarías cada uno de estos casos?*, primero hay que analizar el número total de filas del dataset que se está analizando:

```{r}
nrow = nrow(ttc)
```
El número total de filas con las que cuenta el dataset son: `r nrow`

Teniendo en cuenta la dimensión del dataframe y el número de valores faltantes, procedemos a realizar las siguientes consideraciones:

* En el caso de la variable **Age**, al contar con una proporción de 19% de valores faltantes, al ser una proporción baja, se realizará una imputación de dichos valores. Dicha imputación será a través del estimador de la mediana, para evitar sesgos causadps por valores atípicos, y dicha imputación se dividirá por clases, es decir, se calcularán la mediana de edad resultante en cada una de las clases y dependiendo de si el valor faltante pertenece a una clase u otra se le imputará la mediana resultante de la edad en dicha clase.

* En el caso de la variable **Cabin**, al tratarse de más de un 70% de valores nulos o no válidos, dicha variable será eliminada del conjunto de datos a tratar, ya que no tenemos suficientte información en la que basarnos (un 30% de los casos) para realizar una imputación.

* Por último, para la variable **Embarked**, al tratarse únicamente de 2 casos con respecto al total que son `r nrow, se eliminarán aquellas filas con dicho valor a nulo, pues al ser una cantidad tan pequeña, no merece la pena realizar una imputación.

A continuación procedemos a realizar los cambios comentados:

Primero comenzaremos con la eliminación de la variable **Cabin**

```{r}
ttc$Cabin <- NULL
head(ttc)
```

Ahora procederemos a eliminar aquellas filas donde la variable **Embarked** tiene un valor no válido:

```{r}
ttc <- ttc[!is.na(ttc$Embarked),]
colSums(is.na(ttc))

```

Por último, procedemos a realizar la imputación de la variable **Age**:

```{r}
imputationFunct <- function(x){
    if (is.na(x["Age"])){
      x["Age"]<- median(ttc$Age[ttc$Pclass==x["Pclass"] & !is.na (ttc$Age)])
    } else{
      x<-x
    }
  return (x["Age"])
}

ttc$Age <- apply(ttc,1,imputationFunct)
ttc$Age <- as.numeric(ttc$Age)
sapply(ttc,function(x) sum(is.na(x)))
```

## 3.2 Identificación y tratamiento de valores extremos

Una vez analizados y resueltos los valores faltantes del dataset a analizar, se procede a comprobar si existen valores atípicos en el mismo. Para ello, primero representaremos las variables numéricas con un diagrama de cajas y bigotes, lo cual nos permitirá visualizar gráficamente a simple vista si existen valores atípicos.

```{r}
# Boxplot para la variable Age
summary(ttc$Age)
ggplot(data = ttc, aes(y = Age)) +
  geom_boxplot(outlier.colour = "red") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  ggtitle("Passenger Age Boxplot") +
  theme(plot.title = element_text(size = 20, hjust = 0.5))

# Boxplot para la variable SibSp
summary(ttc$SibSp)
ggplot(data = ttc, aes(y = SibSp)) +
  geom_boxplot(outlier.colour = "red") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  ggtitle("Passenger sibings/spouses Boxplot") +
  theme(plot.title = element_text(size = 20, hjust = 0.5))

# Boxplot para la variable Parch
summary(ttc$Parch)
ggplot(data = ttc, aes(y = Parch)) +
  geom_boxplot(outlier.colour = "red") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  ggtitle("Passenger parents/children Boxplot") +
  theme(plot.title = element_text(size = 20, hjust = 0.5))

# Boxplot para la variable Fare
summary(ttc$Fare)
ggplot(data = ttc, aes(y = Fare)) +
  geom_boxplot(outlier.colour = "red") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  ggtitle("Passenger paid Fare Boxplot") +
  theme(plot.title = element_text(size = 20, hjust = 0.5))
```

Una vez representadas las diferentes variables numéricas, procedemos a extraer las conclusiones oportunas de cada una de ellas. Cuando existen valores atípicos en los datos, pueden darse debido a varias opciones, puede ser porque son valores tomados con una unidad diferente que haga que algunos casos difieran de manera atípica de otros, puede que esos valores representen un valor faltante o nulo o puede que dichos valores formen parte de la muestra y por lo tanto sean valores reales y que hay que tener en cuenta a la hora de realizar los diferentes análisis. También puede darse el caso que sean valores que por el contexto se denote que no han sido tomados correctamente (como por ejemplo una edad de 150 años).

En este caso, nos encontramos con que tenemos valores atípicos en todas las variables numéricas, aunque sí que es cierto que en algunas de ellas dichos valores se encuentran más aislados, como es el caso de la variable **Fare**, que indica la tarifa del pasajero/a.

* En el caso de la variable **Age**, vemos que la mediana se encuentra apróximadamente entre los 25 años, pero que existen valores atípicos a partir de 60 y que hay casos de pasajeros hasta con 80 años. Sí que es verdad que se trata de un valor atípico con respecto a la mayoría de personas que se encuentran en el barco, pero no es un valor imposible de encontrar, por lo que se considera que forma parte del conjunto de datos y que se tiene que tener en cuenta a la hora de realizar el análisis.

* En el caso de la variable **Sibing/spouses** el valor más destacado es el caso de 8. Sí que es verdad que se trata de un valor poco casual, pero puede darse el caso de que una persona tenga 7 hermanos/as y una esposa, o múltiples combinaciones, es decir, a simple vista, no parece ser un valor irreal, por lo que se considera que también se debe tener en cuenta para el análisis.

* En el caso de la variable **Parents/children** pasa un poco como con la variable anterior, el valor máximo es 6 pero no se trata de un valor imposible o improbable, y más por la época en la que se basan los datos, en la que tener 5 o 6 hijos era algo común, por lo que no se considera oportuno realizar ningún cambio en dichos valores.

* Por último, la variable **Fare** resulta ser la variable que contiene los valores atípicos que más se alejan de la desviación estándar de la misma, pues ya de por sí un valor por encima de los 250 resulta ser bastante atípico (según los datos), con lo que en el caso de estar por encima de 500, sitúa dicho valor demasiado alejado de los demás. Dado el significado de la variable y el contexto, puede tratarse perfectamente de un valor real, ya que en los cruceros existen pasajes muy lujosos que tienen un precio muy por encima de un pasaje estándar. No obstante, si que es cierto, que aunque pueda tratarse de valores reales, al estar tan extremadamete alejado de la desviación estándar de la población, puede hacer que los diferentes análisis que se apliquen estén sesgados por dichos valores.

A continuación se procede a estudiar cuantos casos de la variable **Fare** se encuentran por encima de 500 y a realizar una comparación del resultado obtenido por una medida de dispersión robusta a la presencia de valores atípicos, la mediana, con una no robusta a ellos, la media.


```{r}
outlier_cases = nrow(ttc[ttc$Fare > 500,])
mean_Fare = mean(ttc$Fare)
median_Fare = median(ttc$Fare)

outlier_cases
mean_Fare
median_Fare
```

Como se puede observar, el número total de casos atípicos son `r outlier_cases` en todo el dataset.

Por otro lado, el valor obtenido por la media es de `r mean_Fare`, mientras que por la mediana es de `r median_Fare`. Si comparamos ambos resultado, podemos ver que el valor obtenido por la media es apróximadamente el doble que el obtenido por la mediana, lo que indica que los valores atípicos están sesgando dicha medida de dispersión, pero dicho sesgo no se debe a los 3 casos que se encuentran por encima de 500, si que es cierto que influirán, pero el grueso del sesgo se debe que existen muchos casos por encima de la mediana.

Al tratarse de tan pocos casos de los que se encuentran exageradamente desviados (3) y al parecer por el contexto que pueden tratarse de valores reales, se considera que deben ser utilizados para los distintos análisis o métodos estadísticos que se realicen, pero que se deberá tener en cuenta su presencia para aplicar análisis que sean robustos a la presencia de valores atípicos. Pues realizar una imputación de todos los valores que son realmente atípicos o eliminarlos, conllevaría una gran pérdida de información que no es necesaria.


# 4. Análisis de los datos.

A continuación, procederemos a realizar una visualización de las diferentes columnas o variables que forman el dataset, para ver como se distribuyen las mismas.

Comenzaremos por aquellas variables categóricas o cualitativas, estas son:

```{r}
factors = unlist(lapply(ttc, is.factor))
which(factors, arr.ind = TRUE)

```

Procedemos a continuación a representar cada una de ellas:

```{r}

mytableSex <- table(ttc$Sex)
pctSex <- round(mytableSex/sum(mytableSex)*100)
lblsSex <- paste(names(mytableSex), "\n", pctSex, sep="")
lblsSex <- paste (lblsSex, '%', sep="")
pie(mytableSex, labels = lblsSex,
    main="Distribución de la variable Sex\n", col=c("brown4","darkblue"))

mytableSurvived <- table(ttc$Survived)
pctSurvived <- round(mytableSurvived/sum(mytableSurvived)*100)
lblsSurvived<- paste(names(mytableSurvived), "\n", pctSurvived, sep="")
lblsSurvived <- paste (lblsSurvived, '%', sep="")
pie(mytableSurvived, labels = lblsSurvived,
    main="Distribución de la variable Survived\n", col = c("coral","cyan3"))


tablePclass<-table(ttc$Pclass)
dfPclass<-data.frame(tablePclass)

p<-ggplot(data=dfPclass, aes(x=Var1, y=Freq)) +
  geom_bar(stat="identity", fill="#00b159")+
  theme_minimal()+
  xlab("Clase")+
  ylab("Número de pasajeros")
p

tableEmb<-table(ttc$Embarked)
dfEmb<-data.frame(tableEmb)

p<-ggplot(data=dfEmb, aes(x=Var1, y=Freq)) +
  geom_bar(stat="identity", fill="#00aedb")+
  theme_minimal()+
  xlab("Puerta de embarque")+
  ylab("Número de pasajeros")
p



```

De las gráficas anteriores podemos obtener las siguientes conclusiones:

* Hay una mayor proporción de hombres que de mujeres a bordo.
* La mayoría de los personas que iban a bordo no sobrevivieron.
* La mayoría de las personas viajaron en tercera clase, y el número de personas que viajaban en segunda y en primera clase era muy similar.
* La gran mayoría de pasajeros entraron por la puerta de embarque "S"


Una vez representadas las variables categóricas, procedemos a representar las variables continuas del dataset, las cuales son:

```{r}
numerics = unlist(lapply(ttc, is.numeric))
which(numerics, arr.ind = TRUE)
```

De todas las variables que han resultado ser numéricas, representaremos todas menos la variable **PassengerId** que indica únicamente el identificador de cada pasajero o pasajera.


```{r}
# Histograma para la variable Age
ggplot(ttc, aes(x = Age)) + 
  geom_histogram(aes(y = ..density..)) +
  geom_density(alpha = 0.1, fill = "blue") + 
  ggtitle("Passengers Age Density Histogram") +
  theme(plot.title = element_text(size = 20, hjust = 0.5))

# Histograma para la variable SibSp
ggplot(ttc, aes(x = SibSp)) + 
  geom_histogram(aes(y = ..density..)) +
  geom_density(alpha = 0.1, fill = "green") + 
  ggtitle("Passengers sibings/spouses Density Histogram") +
  theme(plot.title = element_text(size = 20, hjust = 0.5))

# Histograma para la variable Parch
ggplot(ttc, aes(x = Parch)) + 
  geom_histogram(aes(y = ..density..)) +
  geom_density(alpha = 0.1, fill = "darkred") + 
  ggtitle("Passengers parents/children Density Histogram") +
  theme(plot.title = element_text(size = 20, hjust = 0.5))

# Histograma para la variable Fare
ggplot(ttc, aes(x = Fare)) + 
  geom_histogram(aes(y = ..density..)) +
  geom_density(alpha = 0.1, fill = "yellow") + 
  ggtitle("Passengers paid Fare Density Histogram") +
  theme(plot.title = element_text(size = 20, hjust = 0.5))
```

De las gráficas anteriores podemos obtener las siguientes conclusiones:

* La variable **Age** se distribuye apróximadamente de una forma normal.
* Las demás variables numéricas presentan una distribución unimodal sesgada hacia la izquierda.

Para una visualizacion general de los datos, podemos representar graficamente los supervivientes agrupados por diversas variables.  

```{r}
# Por ejemplo, la frecuencia de supervivientes por Sexo
ggplot(as.data.frame(table(ttc$Survived, ttc$Sex)), aes(Var2, Freq, fill=Var1)) + 
  geom_bar(stat="identity") +
  scale_fill_discrete(name = "Passenger Survived?", labels = c("No", "Yes")) +
  ggtitle("Passenger Survival Frequency by Sex") +
  theme(plot.title = element_text(size = 20, hjust = 0.5)) +
  xlab("Passenger Sex") + ylab("Frequency")

# O la frecuencia de supervivientes por Clase
ggplot(as.data.frame(table(ttc$Survived, ttc$Pclass)), aes(Var2, Freq, fill=Var1)) + 
  geom_bar(stat="identity") +
  scale_fill_discrete(name = "Passenger Survived?", labels = c("No", "Yes")) +
  ggtitle("Passenger Survival Frequency by Class") +
  theme(plot.title = element_text(size = 20, hjust = 0.5)) +
  xlab("Passenger Class") + ylab("Frequency")

# O incluso la frecuencia de supervivientes por puerto de embarque
ggplot(as.data.frame(table(ttc$Survived, ttc$Embarked)), aes(Var2, Freq, fill=Var1)) + 
  geom_bar(stat="identity") +
  scale_fill_discrete(name = "Passenger Survived?", labels = c("No", "Yes")) +
  ggtitle("Passenger Survival by Port of Embarcation") +
  theme(plot.title = element_text(size = 20, hjust = 0.5)) +
  xlab("Passenger Port of Embarcation") + ylab("Frequency")

# Tambien por el grupo de Edad, aunque previamente debemos discretizar la variable Age 
# ya que es numerica continua.

ttc$AgeD <- discretize(ttc$Age, 
                       method = "cluster", breaks = 3, labels=c("Young", "MidAge", "Old"))

ggplot(as.data.frame(table(ttc$Survived, ttc$AgeD)), aes(Var2, Freq, fill=Var1)) + 
  geom_bar(stat="identity") +
  scale_fill_discrete(name = "Passenger Survived?", labels = c("No", "Yes")) +
  ggtitle("Passenger Survival by Age Group") +
  theme(plot.title = element_text(size = 20, hjust = 0.5)) +
  xlab("Passenger Age Group") + ylab("Frequency")

# Otra grafica interesante puede ser aquella que muestre la frecuencia de supervivencia 
# dependiendo de si el pasajero tenia familiares con el en el barco o viajaban solos

ggplot(as.data.frame(table(ttc$Survived, ttc$SibSp)), aes(Var2, Freq, fill=Var1)) + 
  geom_bar(stat="identity") +
  scale_fill_discrete(name = "Passenger Survived?", labels = c("No", "Yes")) +
  ggtitle("Passenger Survival by number of Siblings/Spouses") +
  theme(plot.title = element_text(size = 14, hjust = 0.5)) +
  xlab("Passenger number of siblings/Spouses") + ylab("Frequency")

ggplot(as.data.frame(table(ttc$Survived, ttc$Parch)), aes(Var2, Freq, fill=Var1)) + 
  geom_bar(stat="identity") +
  scale_fill_discrete(name = "Passenger Survived?", labels = c("No", "Yes")) +
  ggtitle("Passenger Survival by number of Parents/Children") +
  theme(plot.title = element_text(size = 14, hjust = 0.5)) +
  xlab("Passenger number of Parents/Children") + ylab("Frequency")

# O en general, si el pasajero tenia familia a bordo
ttc$PassengerFamily <- ifelse(ttc$SibSp != 0 | ttc$Parch != 0, 'FamilyOnBorad', "AlonePassenger") 
table(ttc$Survived, ttc$PassengerFamily)
ggplot(as.data.frame(table(ttc$Survived, ttc$PassengerFamily)), aes(Var2, Freq, fill=Var1)) + 
  geom_bar(stat="identity") +
  scale_fill_discrete(name = "Passenger Survived?", labels = c("No", "Yes")) +
  ggtitle("Passenger Survival by Family On Board") +
  theme(plot.title = element_text(size = 14, hjust = 0.5)) +
  xlab("Passenger Family On Board") + ylab("Frequency")

# Por ultimo una relacion interesante, es la frecuencia de supervicencia asociada
# a la longitud del nombre del pasajero, bajo una premisa inicial de que, cuanto
# mas largo fuera el nombre, el pasajero podria tener una clase social mas elevada
ttc$NameLength <- vector("numeric", nrow(ttc))
for (i in 1:nrow(ttc)) {
  ttc$NameLength[i] <- nchar(as.character(ttc$Name)[i])
}
ttc$NameLengthD <- discretize(ttc$NameLength, 
           method = "cluster", breaks = 4, labels=c("ShortName (<21)", 
                                                    "MediumName (<28)", 
                                                    "LongName (<40)", 
                                                    "VeryLongName (<82)"))
ggplot(as.data.frame(table(ttc$Survived, ttc$NameLengthD)), aes(Var2, Freq, fill=Var1)) + 
  geom_bar(stat="identity") +
  scale_fill_discrete(name = "Passenger Survived?", labels = c("No", "Yes")) +
  ggtitle("Passenger Survival by Name Length") +
  theme(plot.title = element_text(size = 20, hjust = 0.5)) +
  xlab("Passenger Name Length, number of characters") + ylab("Frequency")
```

Por ultimo en el proceso de exploracion de los datos, se puede obtener una matriz de correlacion sobre las variables numericas del dataset:
```{r}
ttc_num <- subset(ttc, select=c(Age, SibSp, Parch, Fare))
ttccorr <- cor(ttc_num)
ggcorrplot(ttccorr, method = "circle")
```
## 4.1. Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).

Se plantean 2 tipos de estrategias de analisis de los datos:

1. Analisis estadistico inferencial centrado en 2 contrastes de Hipotesis.

2. Modelizacion predictiva aplicando 3 modelos de clasificacion (regresion logistica, Random Forest y SupportVector Machine - SVM).

A continuacion se desarrollan cada uno de ellos:

## 4.2. Comprobación de la normalidad y homogeneidad de la varianza.

Los chequeos de normalidad y homogeneidad de varianza son importantes para aplicar las diferentes herramientas y Tests de Hipótesis. En general usaremos pruebas Z-Test que requieren normalidad de las variables y el cálculo del estadístico usa una fórmula u otra dependiendo de si las varianzas son homogéneas o no.

Para el análisis de contrates de hipótesis sobre la media usamos una métrica especifica: el ratio de supervivencia. Esto es, si tomamos una muestra aleatoria de pasajeros bajo una condición fija (mismo sexo, o misma clase) y obtenemos la media de la variable Survived, dicha media nos dará el ratio de supervivencia sobre esa sub muestra. 

Por ejemplo, si tomamos una muestra de 100 pasajeros de  primera clase y obtenemos la media de la variable Survived:
```{r}
mean(as.numeric(as.character(ttc[sample(which(ttc$Pclass == 1),100),]$Survived)))
```
Este valor nos dice la media del ratio de supervivencia de esa muestra en particular.

El teorema del límite central establece que, tomando un número suficiente de estas submuestras, esta media del ratio de superviviencia se distribuye siguiendo una normal. Vamos a aplicar contrastes de hipótesis atendiendo a grupos por Clase (Primera y Tercera) y Sexo.  

### 4.2.1 Comprobación de la normalidad y la homogenidad de la varianza en muestras de supervivencia por la clase del pasajero

Para comprobar la normalidad y la homegeneidad de la varianza, se genera un array de medias sobre 100 submuestras aleatorias de 100 pasajeros de cada una de las clases, y se comprobará la normalidad y la homgenidad sobre dicho array, de manera que si sobre ese conjunto aleatorio obtenido se cumple, se cumplirá para todo el conjunto, según el teorema del límite central.

```{r}
# Generamos un array de medias sobre 100 submuestras aleatorias de 100
# pasajeros de primera clase cada submuestra.
iter <- 100
vars <- 1
First_class_SampleMeans <- matrix(ncol=vars, nrow=iter)
for(i in 1:iter){
  set.seed(i*16)
  First_class_SampleMeans[i,] <- mean(as.numeric(as.character
                                                 (ttc[sample(which
                                                             (ttc$Pclass == 1)
                                                             ,100),]$Survived)))
}
mean(First_class_SampleMeans)
First_class_SampleMeans <- data.frame(First_class_SampleMeans)

# Hacemos lo mismo pero para 100 submuestras aleatorias de 100 pasajeros de tercera clase 
# cada submuestra.
Third_class_SampleMeans <- matrix(ncol=vars, nrow=iter)
for(i in 1:iter){
  set.seed(i*16)
  Third_class_SampleMeans[i,] <- mean(as.numeric(as.character
                                                 (ttc[sample(which
                                                             (ttc$Pclass == 3)
                                                             ,100),]$Survived)))
}
mean(Third_class_SampleMeans)
Third_class_SampleMeans <- data.frame(Third_class_SampleMeans)

# Revisamos la distribucion de estas variables a nivel grafico de densidad:
SF_FirstClass_Density <- ggplot(First_class_SampleMeans, aes(x = First_class_SampleMeans)) + 
  geom_histogram(aes(y = ..density..)) +
  geom_density(alpha = 0.5, fill = "green") + 
  ggtitle("Survival rate Frequency in First Class") +
  theme(plot.title = element_text(size = 10, hjust = 0.5))

SF_ThirdClass_Density <- ggplot(Third_class_SampleMeans, aes(x = Third_class_SampleMeans)) + 
  geom_histogram(aes(y = ..density..)) +
  geom_density(alpha = 0.5, fill = "darkred") + 
  ggtitle("Survival rate Frequency in Third Class") +
  theme(plot.title = element_text(size = 10, hjust = 0.5))

ggarrange(SF_FirstClass_Density , SF_ThirdClass_Density)
```

Para confirmar si ambas distribuciones pueden aproximarse a una normal, aplicamos el test de Shapiro sobre ambas:

Este test toma como:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _Hipotesis Nula:_ La Variable se distribuye segun una Normal.  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _Hipotesis Alternativa:_ La variable NO se distribuye segun una normal.
```{r}
shapiro.test(First_class_SampleMeans$First_class_SampleMeans)
shapiro.test(Third_class_SampleMeans$Third_class_SampleMeans)

```
A un nivel de confianza del 95%, los p-values obtenidos son superiores al nivel de signifación (p-value > 0.05), por lo que no podemos descartar la Hipotesis Nula (es decir, no podemos descartar que estas distribuciones son normales).

Alternativamente podemos usar los Quantile-Quantile Plots o Q-Q Plots para ver la correlación entre cada variable y una normal, observando que se ajustan a la recta en 45 grados (son variables distribuidas normalmente).

```{r}
qqnorm(First_class_SampleMeans$First_class_SampleMeans)
qqline(First_class_SampleMeans$First_class_SampleMeans)
qqnorm(Third_class_SampleMeans$Third_class_SampleMeans)
qqline(Third_class_SampleMeans$Third_class_SampleMeans)
```

De manera análoga podemos verificar la homogeneidad de varianzas en ambas muestras utilizando el test de Bartlett:
```{r}
bartlett.test(list(First_class_SampleMeans$First_class_SampleMeans
                   ,Third_class_SampleMeans$Third_class_SampleMeans))

```
En este caso, el p-value es superior a nuestro nivel de significación (0.05) por lo que no podemos descartar que la diferencia entre las varianzas de ambas muestras sea nula

### 4.2.2 Comprobación de la normalidad y la homogenidad de la varianza en muestras de supervivencia por el sexo del pasajero

Al igual que en el apartado anterior, para comprobar la normalidad y la homegeneidad de la varianza, se genera un array de medias sobre 100 submuestras aleatorias de 100 pasajeros de cada uno de los sexos y posteriormente se comprueba la normalidad y la homogenidad de estos arrays obtenidos.

```{r}
# Generamos un array de medias sobre 100 submuestras aleatorias de 100
# pasajeros de sexo masculino.
iter <- 100
vars <- 1
Male_sex_SampleMeans <- matrix(ncol=vars, nrow=iter)
for(i in 1:iter){
  set.seed(i*16)
  Male_sex_SampleMeans[i,] <- mean(as.numeric(as.character
                                                 (ttc[sample(which
                                                             (ttc$Sex == 'male')
                                                             ,100),]$Survived)))
}
mean(Male_sex_SampleMeans)
Male_sex_SampleMeans <- data.frame(Male_sex_SampleMeans)

# Hacemos lo mismo pero para 100 submuestras aleatorias de 100 pasajeros de sexo
# femenino.
Female_sex_SampleMeans <- matrix(ncol=vars, nrow=iter)
for(i in 1:iter){
  set.seed(i*16)
  Female_sex_SampleMeans[i,] <- mean(as.numeric(as.character
                                                 (ttc[sample(which
                                                             (ttc$Sex == 'female')
                                                             ,100),]$Survived)))
}
mean(Female_sex_SampleMeans)
Female_sex_SampleMeans <- data.frame(Female_sex_SampleMeans)

# Revisamos la distribucion de estas variables a nivel grafico de densidad:
SF_MaleSex_Density <- ggplot(Male_sex_SampleMeans, aes(x = Male_sex_SampleMeans)) + 
  geom_histogram(aes(y = ..density..)) +
  geom_density(alpha = 0.5, fill = "green") + 
  ggtitle("Survival rate Frequency for Males") +
  theme(plot.title = element_text(size = 10, hjust = 0.5))

SF_FemaleSex_Density <- ggplot(Female_sex_SampleMeans, aes(x = Female_sex_SampleMeans)) + 
  geom_histogram(aes(y = ..density..)) +
  geom_density(alpha = 0.5, fill = "darkred") + 
  ggtitle("Survival rate Frequency for Females") +
  theme(plot.title = element_text(size = 10, hjust = 0.5))

ggarrange(SF_MaleSex_Density , SF_FemaleSex_Density)
```

Para comprobar la normalidad, procedemos a aplicar el test de Shapiro.

```{r}
shapiro.test(Male_sex_SampleMeans$Male_sex_SampleMeans)
shapiro.test(Female_sex_SampleMeans$Female_sex_SampleMeans)

```
Según los resultados obtenidos, no podemos descartar la Hipótesis Nula de Normalidad.

Además, como en el apartado anterior, podemos ver que estos datos se comportan de una forma normal aplicando los Quantile-Quantile Plots o Q-Q Plots.

```{r}
qqnorm(Male_sex_SampleMeans$Male_sex_SampleMeans)
qqline(Male_sex_SampleMeans$Male_sex_SampleMeans)
qqnorm(Female_sex_SampleMeans$Female_sex_SampleMeans)
qqline(Female_sex_SampleMeans$Female_sex_SampleMeans)
```

De manera análoga podemos verificar la homogeneidad de varianzas en ambas muestras:
```{r}
# Test de Homogeneidad de Varianzas
bartlett.test(list(Male_sex_SampleMeans$Male_sex_SampleMeans
                   ,Female_sex_SampleMeans$Female_sex_SampleMeans))

```
En este caso, el p-value es superior a nuestro nivel de significación (0.05) por lo que no podemos descartar que la diferencia entre las varianzas de ambas muestras sea nula.


## 4.1 Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).

Tras analizar y explorar este dataframe, teniendo en cuenta las variables con las que se cuentan tras realizar la limpieza, hemos considerado interesante realizar los siguientes análisis:

* **Test de hipótesis sobre la proporción de hombres que sobrevivieron frente a la proporción de mujeres** que lo hicieron, planteando como hipótesis alternativa que la proproción de hombres que sobrevivieron es mayor que la proporción de mujeres.

* **Test de hipótesis sobre la proporción de personas que pertenecen a las distintas clases**, planteando como hipótesis alternativa que la proporción de personas que sobrevivieron en primera clase es mayor que la proporción de personas que sobrevivieron de las dos clases restantes.

* **Modelo de Regresión Logística** tratando de predecir si un pasajero sobrevivirá o no.

* **Comparación de modelo de Bosque Aleatorio contra un modelo de Máquinas de Vectores de soporte** para ver cual ofrece mejores resultados.


## 4.3 Aplicación de pruebas estadísticas para comparar los grupos de datos.

### 4.3.1 Tests de hipótesis

#### 4.3.1.1 Tests de hipótesis sobre la media de supervivencia según las clases

Planteamos como Hipótesis:  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _Hipótesis Nula:_ La media del ratio de supervivencia de los pasajeros en primera clase es la misma que la media del ratio de supervivencia para los pasajeros de tercera clase.  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _Hipótesis Alternativa:_ La media del ratio de supervivencia de los pasajeros en primera clase es superior a la media del ratio de supervivencia para los pasajeros de tercera clase.

A continuación, aplicamos un Z test de una cola sobre dos medias con varianzas muestrales distintas, a pesar de que el test de Barlett no descartaba la posibilidad de que estas fuesen iguales.

```{r}
z.test(First_class_SampleMeans$First_class_SampleMeans, 
       Third_class_SampleMeans$Third_class_SampleMeans, 
       sigma.x=sqrt(var(First_class_SampleMeans$First_class_SampleMeans)),
       sigma.y=sqrt(var(Third_class_SampleMeans$Third_class_SampleMeans)),
       alternative="greater",
       conf.level = 0.95)

```
El resultado obtenido por el test es que el p-value es inferior a nuestro nivel de significación (0.05). Lo que quiere decir, que con un nivel de confianza del 95%, podemos descartar la hipotesis nula y aceptar la alternativa:

- **La media del ratio de supervivencia de los pasajeros en primera clase es superior a la  media del ratio de supervivencia para los pasajeros de tercera clase**

#### 4.3.1.2 Tests de hipótesis sobre la media de supervivencia según el sexo

Para este contraste fijamos las siguientes hipótesis:  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _Hipótesis Nula:_ La media del ratio de supervivencia de los hombres es la misma que la media del ratio de supervivencia para las mujeres.  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _Hipótesis Alternativa:_ La media del ratio de supervivencia de los hombres es inferior a la media del ratio de supervivencia para las mujeres. 

A continuación, aplicamos un Z test de una cola sobre dos medias con varianzas muestrales distintas, a pesar de que el test de Barlett no descartaba la posibilidad de que estas fuesen iguales.

```{r}
z.test(Male_sex_SampleMeans$Male_sex_SampleMeans, 
       Female_sex_SampleMeans$Female_sex_SampleMeans, 
       sigma.x=sqrt(var(Male_sex_SampleMeans$Male_sex_SampleMeans)),
       sigma.y=sqrt(var(Female_sex_SampleMeans$Female_sex_SampleMeans)),
       alternative="less",
       conf.level = 0.95)
# El resultado es que el p-value es inferior a nuestro nivel de confianza. Esto es, con un 
# nivel de confianza del 95%, podemos descartar la hipotesis nula y aceptar la 
# alternativa:
# La media del ratio de supervivencia de los hombres es inferior a la media del ratio de 
# supervivencia para las mujeres
```
El resultado obtenido por el test es que el p-value es inferior a nuestro nivel de significación (0.05). Lo que quiere decir, que con un nivel de confianza del 95%, podemos descartar la hipotesis nula y aceptar la alternativa:

-  **La media del ratio de supervivencia de los hombres es inferior a la media del ratio de supervivencia para las mujeres**

### 4.3.2 Modelos

#### 4.3.2.1 Acotación principal de variables a utilizar



De todas las variables con las que cuenta el dataframe que se está analizando en esta práctica, se descartan de primeras las siguientes variables para la construcción del modelo predictivo:

* **PassengerId**
* **Name**
* **Ticket**

Estas variables no tiene sentido utilizarlas para construir un modelo predictivo porque son variables que identifican a cada uno de los pasajeros y pasajeras.

Por lo tanto, las únicas variables que tiene sentido poder utilizar para la construcción del modelo predictivo son las siguientes:

* **Pclass**
* **Sex**
* **Age**
* **SibSp**
* **Parch**
* **Fare**
* **Embarked**

Y la variable **Survived**, que nos servirá como variable objetivo del modelo.

De todas las posibles variables a utilizar que se han citado, se considera que la variable **Fare** y la variable **Pclass** vienen a indicar prácticamente la misma información o muy similar, pues la variable **Pclass** indica la clase en la que se encuentra el pasajero/a y la variabel **Fare** el precio del billete o ticket de embarque. Normalmente a mayor precio del billete, más alta será la clase, aunque puede que existan casos que sean precios más altos pero pertenezcan a una clase baja y que dicho precio se haya visto incrementado porque se vendió durante los últimos días disponibles de venta del mismo. Pero de normal, a un mayor precio, más alta será la clase, lo que quiere decir que ambas variables están muy relacionadas entre sí. En los modelos predictivos, utilizar variables que de alguna manera indiquen la misma información puede hacer que empeore el modelo o en el mejor de los casos, no aportará mucha información al mismo, por lo que conviene elegir una de estas dos variables. En este caso, como el modelo predictivo es de clasificación, tiene más sentido utilizar la variable **Pclass** y eliminar por tanto la variable **Fare**.

De esta manera, las únicas variables que pueden tener sentido utilizar para la construcción del modelo predictivo son las siguientes:

* **Survived** (como variable objetivo)

* **Pclass**
* **Sex**
* **Age**
* **SibSp**
* **Parch**
* **Embarked**

De todas estas posibles variables a utilizar, determinaremos cual utilizar o no realizando una selección de características. Para ello, se estudiará la relación de cada una de las variables con la variable objetivo mediante el test ***Chi-squared***, de manera que sólo se utilizarán para el modelo predictivo aquellas variables que podamos afirmar con un grado de confianza determinado que presentan cierta relación con la variable objetivo.


Antes de realizar la selección de características, será necesario convertir aquellas variables numéricas a variables categóricas dividiendo las mismas en intervalos, ya que las variables numéricas no proporcionan mucha información en los modelos de clasificación. 

Se procede a continuación a aplicar dicha conversión para todas las variables numéricas.

#### 4.3.2.2 Data Binning



A la conversión de variables numéricas a variables categóricas agrupando las mismas por intervalos, se le conoce como ***Data Binning*** o **Agrupación de Datos**. Esta técnica, presenta diferentes variantes de aplicación, pero en este caso dividiremos las variables numéricas por intervalos del mismo tamaño.

Comenzaremos con la variable **Age**, dividiendo la misma en rangos de 5 años.

```{r}
ttc$Age <- cut(ttc$Age,breaks = 5*(0:16))
head(ttc$Age)
```

Por otro lado, las variables **Parch** y **SibSp** se dividirán en grupos de 2.

```{r}
ttc$SibSp <- cut(ttc$SibSp,breaks = 2*(0:4), include.lowest = TRUE)
ttc$Parch <- cut(ttc$Parch,breaks = 2*(0:3), include.lowest = TRUE)

head(ttc$SibSp)
head(ttc$Parch)
```

#### 4.3.2.3 Selección de características



Una vez realizadas las conversiones necesarias, como se ha explicado anteriormente, en el apartado **4.3.1**, se procede a aplicar el test **Chi-squared** para cada una de las posibles variables a utilizar para construir el modelo predictivo, con la variable objetivo.

El test **Chi-squared** es un test de hipótesis que consta de las siguientes hipótesis:

* **Hipótesis nula**: Las variables sobre las que se está aplicando el test son independientes una de la otra.

* **Hipótesis alternativa**: Las variables sobre las que se está aplicando el test están relacionadas una con la otra.


El resultado de este test indicará la probabilidad de que la Hipótesis nula se cumpla, y se deberá fijar un nivel de confianza que nos permita rechazar esta o no. Al aplicar este test se suele utilizar un nivel de confianza de un 95%, que será el que utilizaremos nosotros también. De esta manera, rechazaremos la Hipótesis nula cuando la probabilidad de que esta se cumpla sea menor a un 5%. Hablamos de probabilidades porque se está midiendo la relación de dos variables aleatorias, por lo que no se puede asegurar sin un margen de error que estas están relacionadas o  no.

A continuación, se procede a aplicar dicho test para cada una de las variables candidatas a formar el modelo predictivo.

El orden que seguiremos para aplicar el test chi-cuadrado, es el siguiente:

* 1. Pclass
* 2. Sex
* 3. Age
* 4. SibSp
* 5. Parch
* 6. Embarked

```{r}
tab_Pclass <- table(ttc$Pclass,ttc$Survived)
chisq_Pclass <- chisq.test(tab_Pclass)
chisq_Pclass
```

Dado que el p-valor obtenido es menor que 0.05, se puede afirmar con un 95% de probabilidad que la variable **Pclass** se encuentra relacionada con la variable **Survived**, por lo que esta será utilizada para formar el modelo predictivo.

```{r}
related_features <- c("Pclass")

```


```{r}
tab_Sex <- table(ttc$Sex, ttc$Survived)
chisq_sex <- chisq.test(tab_Sex)
chisq_sex
```

Dado que el p-valor obtenido es menor que 0.05, se puede afirmar con un 95% de probabilidad que la variable **Sex** se encuentra relacionada con la variable **Survived**, por lo que esta será utilizada para formar el modelo predictivo.

```{r}
related_features <- c(related_features,"Sex")

```


```{r}
tab_Age <- table (ttc$Age, ttc$Survived)
chisq_Age <- chisq.test(tab_Age)
chisq_Age
```

Dado que el p-valor obtenido es menor que 0.05, se puede afirmar con un 95% de probabilidad que la variable **Age** se encuentra relacionada con la variable **Survived**, por lo que esta será utilizada para formar el modelo predictivo.

```{r}
related_features <- c(related_features,"Age")

```


```{r}
tab_SibSp <- table (ttc$SibSp, ttc$Survived)
chisq_SibSp <- chisq.test(tab_SibSp)
chisq_SibSp

```

Dado que el p-valor obtenido es menor que 0.05, se puede afirmar con un 95% de probabilidad que la variable **SibSp** se encuentra relacionada con la variable **Survived**, por lo que esta será utilizada para formar el modelo predictivo.

```{r}
related_features <- c(related_features,"SibSp")

```



```{r}
tab_Parch <- table(ttc$Parch, ttc$Survived)
chisq_Parch <- chisq.test(tab_Parch)
chisq_Parch
```

Dado que el p-valor obtenido es mayor que 0.05, no se puede afirmar que la variable **Parch** se encuentra relacionada con la variable **Survived**, por lo que esta no será utilizada para formar el modelo predictivo.

```{r}
tab_Embarked <- table(ttc$Embarked, ttc$Survived)
chisq_Embarked <- chisq.test(tab_Embarked)
chisq_Embarked
```

Dado que el p-valor obtenido es menor que 0.05, se puede afirmar con un 95% de probabilidad que la variable **Embarked** se encuentra relacionada con la variable **Survived**, por lo que esta será utilizada para formar el modelo predictivo.

```{r}
related_features <- c(related_features,"Embarked")

```



Tras realizar el test a todas las variables que había disponibles para formar el modelo, quedan únicamente para formar este las siguientes:

```{r}
related_features
```

A continuación, procedemos a añadir al vector **related_features** la variable objetivo, para poder obtener del dataframe original todas estas variables que son las que se utilizarán para construir el modelo predictivo.

```{r}
related_features <- c(related_features,"Survived")
ttc_model <- ttc %>% select(related_features)
head(ttc_model)
```

Antes de la aplicación de los modelos, procedemos a preparar el dataset para poder ser utilizado para crear los diferentes modelos predictivos.

```{r}
ttc_vectors <- ttc_model %>%
  mutate_if(is.factor, as.numeric)
head(ttc_vectors)

ttc_vectors$Survived <- as.factor(ttc_vectors$Survived)


ttc_vectors$Survived <- revalue(ttc_vectors$Survived, c("1"="NO", "2"="YES"))
head(ttc_vectors)

train_test_split <- initial_split(ttc_vectors, prop=3/4)


TRAIN <- training(train_test_split)
TEST <- testing(train_test_split)

head(TRAIN)
head(TEST)
```


#### 4.3.2.4 Regresión Logística


A continuación, se procede a la creación del modelo predictivo regresión logística.

```{r}
control <- trainControl(method="repeatedcv", number=10, repeats=3, 
                        summaryFunction = twoClassSummary, classProbs = TRUE)
glm <- train(Survived~., data = TRAIN, method="glm", trControl=control)
```

Este modelo de regresión logística, se entrena aplicando para ello una validación cruzada anidada. De esta forma, esta búsqueda de mejores hiperparámetros se realiza dividiendo el conjunto de datos de entrenamiento en 10 bloques, de esos 10 bloques se utilizará en cada iteración uno de ellos para probar el modelo y el resto para entrenar el mismo. Este proceso se repetirá 3 veces y eso nos permitirá obtener de manera realista como se comporta el modelo creado, pues probándolo únicamente con la parte dedicada a los test, dicha parte puede estar sesgada. Por lo que de esta manera, nos dará una visión más realista de como funciona el modelo. 

Este proceso, además debería buscar los mejores hiperparámetros para el modelo basándose en la métrica AUC, pero la regresión logística en el paquete **Caret**, no permite especificar ningún parámetro de ajuste, por lo que no se podrá aprovechar al 100% el potencial de esta función.

Los resultados obtenidos por el modelo tras entrenar el mismo son los siguientes:

```{r}
glm
```

Estos resultados son la media de los resultados obtenidos al aplicar la validación cruzada anidada.

Como se puede observar, se tratan de resultados bastante buenos.

A continuación, se procede a probar el modelo creado y obtener las métricas resultantes con los datos destinados para testear el modelo.

```{r}
glm.TEST <- predict(glm, TEST)

class_glm <- predict(glm, TEST)

confusionMatrix(data=class_glm, TEST$Survived)
```

#### 4.3.2.4 Bosque Aleatorio

A continuación, se procede a la creación del modelo predictivo utilizando el algoritmo de bosque aleatorio.

```{r}
rf <- train(Survived~., data = TRAIN, method="rf", trControl=control, 
            tuneLength=4)
rf

```

En este caso, como se puede observar, además de aplicar el método de validación cruzada anidada para validar el modelo, se trata de buscar los mejores valores de los hiperparámetros que permitan al modelo obtener las mejores métricas. En este caso, el hiperparámetro es ***mtry*** y el valor que ha resultado ser mejor, como aparece en la visualización anterior, es el **2**.

Se procede a continuación además a obtener los resultados para los datos destinados para testear el modelo.

```{r}
rf.TEST <- predict(rf, TEST)
class_rf <- predict(rf, TEST)

confusionMatrix(data=class_rf, TEST$Survived)
```

Los resultados obtenidos son mejores aún que en la regresión logística, lo que es normal ya que el algoritmo de bosque aleatorio es un algoritmo más potente que la regresión logística.

#### 4.3.2.5 Máquinas de Vectores de Soporte


A continuación, se procede a la creación del modelo predictivo utilizando el algoritmo de máquinas de vectores de soporte de clasificación.

```{r}

svm_poly <- train(Survived~., data = TRAIN, method="svmPoly", 
                    trControl=control,preProcess = c("center","scale"),
                    tuneLength = 4)
svm_poly

```
En este modelo, al igual que en el anterior, se trata de buscar los mejores hiperparámetros para el mismo, aplicando para ello un algoritmo de validación cruzada anidada. En este caso el hiperparámetro es **C** y el valor que ha resultado tener mejores resultados es cuando este tiene un valor de **0.25**. En este caso, además se ha aplicado un preprocesamiento de centrado y escalado de los datos. Este preprocesado aplica el escalado y centrado sobre los datos de entrenamiento que mejores resultados permita dar.

Se procede a continuación además a obtener los resultados para los datos destinados para testear el modelo.

```{r}
class_svm_poly <- predict(svm_poly, TEST)
confusionMatrix(data=class_svm_poly, TEST$Survived)
```


#### 4.3.2.6 Prueba con el dataset test

Una vez construidos y comparados los modelos, se procede a obtener los resultados para el archivo **test.csv**, aplicando para ello el modelo que mejores resultados ha obtenido, que es el modelo de **bosque aleatorio**.

Previamente a la aplicación del modelo predictivo, este dataset será procesado con los cambios que se aplicaron al dataset **train**, es decir, se realizará un redondeo de las edades que tengan decimales y una imputación de aquellas edades que no se tengan información.

```{r}

ttc_test_origin <- read.csv("./Data/test.csv",na.strings=c(""," ","NA"), 
                     stringsAsFactors = TRUE)
head(ttc_test_origin)

features<-head(related_features,-1)
ttc_test <- ttc_test_origin %>% select(features)
head(ttc_test)


ttc_test$Age <- apply(ttc_test,1,roundValues)
ttc_test$Age <- as.numeric(ttc_test$Age)

imputationFunct_test <- function(x){
  if (is.na(x["Age"])){
    x["Age"]<- median(ttc_test$Age[ttc_test$Pclass==x["Pclass"] & 
                                     !is.na (ttc_test$Age)])
  } else{
    x<-x
  }
  return (x["Age"])
}
ttc_test$Age <- apply(ttc_test,1,imputationFunct_test)
ttc_test$Age <- as.numeric(ttc_test$Age)

ttc_test_vectors <- ttc_test %>%
  mutate_if(is.factor, as.numeric)
head(ttc_test_vectors)


ttc_test_vectors.class <- predict(rf, ttc_test_vectors)
ttc_test_origin$Survived <- ttc_test_vectors.class
ttc_test_df = ttc_test_origin %>% select("PassengerId", "Survived")
ttc_test_df$Survived = revalue(ttc_test_df$Survived, c("YES"=1, "NO"=0))
ttc_test_df$Survived = as.numeric(ttc_test_df$Survived)

write.csv(ttc_test_df,"./Data/test_results.csv", row.names = FALSE)

```


# 5. Representación de los resultados a partir de tablas y gráficas

## 5.2 Tabla resumen de los resultados obtenidos en los modelos predictivos

| Algoritmos                     | ROC       | Sens      | Spec      |
|--------------------------------|-----------|-----------|-----------|
| Regresión Logística            | 0.844145  | 0.8627236 | 0.7026667 |
| Bosque Aleatorio               | 0.8465613 | 0.9404268 | 0.6420513 |
| Máquina de Vectores de Soporte | 0.8372377 | 0.8024593 | 0.7386154 |


# 6. Conclusiones obtenidas

- Con respecto a los modelos predictivos, tras la aplicación de los modelos de: **regresión logística, bosque aleatorio y máquinas de vectores de soporte de clasificación**, el modelo que **mejores resultados** ha obtenido es el modelo que utiliza el algoritmo de **bosque aleatorio**. El modelo de regresión logística fue aplicado para probar los resultados obtenidos con el modelo de clasificación más simple por excelencia, pero los resultados de calidad obtenidos por el mismo han sido bastante buenos, de hecho, mejores que los obtenidos por el modelo de máquinas de vectores de soporte de clasificación, a pesar de que este último es un modelo más potente.

# Contribuciones

| Contribuciones              | Firma |
|-----------------------------|-------|
| Investigación Previa        |![Firma Fran](../FirmaFran.jpg) ![Firma Enrique](../EnriqueOterFirma.jpg)|
| Redacción de las respuestas |![Firma Fran](../FirmaFran.jpg) ![Firma Enrique](../EnriqueOterFirma.jpg)|
| Desarrollo código           |![Firma Fran](../FirmaFran.jpg) ![Firma Enrique](../EnriqueOterFirma.jpg)|